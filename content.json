{"pages":[],"posts":[{"title":"VGG paper takenote","text":"VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITIONTLDR: The authors proposed using the very small filter in the convolution layers make the networks more depths and worked better. Beside that, by using the small filter (3x3), the total of params is decreasing. Key points Replace the large receptive filter in the first layer (5x5, 7x7, 11x11 with big stride) by small filter (3x3). Stack 2 layers 3x3 convolution (without activation) is like 5x5, or 3 layer 3x3 like 7x7, but it make model has less params =&gt; efficient. The authors use 1x1 convolution is the way to increase the non linear of decision funtion without afecting the receptive field of convolution layers. In the paper, the 1x1 is essentially a linear projection onto the space of same dimensionality. The authors conjecture that the model required less epoch to converge, due to implicit regularisation imposed by greater depth and smaller conv filter sizes.","link":"/2020/06/05/VGG-paper-takenote/"},{"title":"MobileNetv1-paper-takenote","text":"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision ApplicationsTL,DR: The authors presented a class of efficient models called MobileNets for mobile and embedded vision applications. Those models are based on a streamlined architecture that uses depth wise separable convolutions to build the light weight models. Beside that, the authors introduced two simple hyperparameters that controle the trade off between latency and accuracy (alpha and p). Key points: Depth wise separable convolution is the convolution that separates the operation into 2 operation. First, convolution for each depth layer. After that, we use 1x1 convolution to combine the input in the depth dimension. The advantage of the depth wise separable convolution is that do not require much more computiation cost, reduce time and size of model. The authors also representd two hyperparams for control efficiently the trade off between latancy and accuracy of model, a and p. Alpha control the size of the model, by controling the number of the filters in each layer of the model. p control the resolution of the input.","link":"/2020/06/05/MobileNetv1-paper-takenote/"}],"tags":[{"name":"Machine Learning, Deep Learning, Computer Vison, paper takenote","slug":"Machine-Learning-Deep-Learning-Computer-Vison-paper-takenote","link":"/tags/Machine-Learning-Deep-Learning-Computer-Vison-paper-takenote/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"}],"categories":[{"name":"Computer Vision","slug":"Computer-Vision","link":"/categories/Computer-Vision/"},{"name":"Machine Learning, Deep Learning, Computer Vison, paper takenote","slug":"Machine-Learning-Deep-Learning-Computer-Vison-paper-takenote","link":"/categories/Machine-Learning-Deep-Learning-Computer-Vison-paper-takenote/"}]}